name: JMeter Performance Tests

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write
  pull-requests: write

jobs:
  performance-test:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Build JMeter Docker image
      run: docker build -t jmeter-test .
      
    - name: Run JMeter Tests
      run: |
        mkdir -p results
        docker run --rm \
          -v "${PWD}/results:/test/results" \
          jmeter-test \
          -n -t /test/k6-api-test-plan.jmx \
          -l /test/results/results.jtl \
          -j /test/results/jmeter.log \
          -e -o /test/results/dashboard

    - name: Extract Test Metrics
      if: github.event_name == 'pull_request'
      run: |
        # Get average response time from results.jtl (elapsed time is in column 2)
        AVG_RESPONSE=$(awk -F',' 'NR>1 {sum+=$2} END {printf "%.2f", sum/(NR-1)}' results/results.jtl || echo "N/A")
        echo "AVG_RESPONSE=$AVG_RESPONSE" >> $GITHUB_ENV
        
        # Get total requests (subtract header line)
        TOTAL_REQUESTS=$(( $(wc -l < results/results.jtl) - 1 ))
        echo "TOTAL_REQUESTS=$TOTAL_REQUESTS" >> $GITHUB_ENV
        
        # Get success rate
        SUCCESS_COUNT=$(grep -c ",true," results/results.jtl || echo "0")
        SUCCESS_RATE=$(awk -v success="$SUCCESS_COUNT" -v total="$TOTAL_REQUESTS" 'BEGIN {printf "%.2f", (success/total)*100}')
        echo "SUCCESS_RATE=$SUCCESS_RATE" >> $GITHUB_ENV

        # Extract other metrics from dashboard/statistics.json if it exists
        if [ -f results/dashboard/statistics.json ]; then
          echo "Found statistics.json"
          cat results/dashboard/statistics.json
        fi

    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      run: |
        PR_COMMENT="## ðŸš€ Performance Test Results

        ### Test Summary
        - **Average Response Time**: ${AVG_RESPONSE:-N/A} ms
        - **Total Requests**: ${TOTAL_REQUESTS:-N/A}
        - **Success Rate**: ${SUCCESS_RATE:-0}%

        ### ðŸ“Š Detailed Results
        - Download results from the Artifacts section below
        - View test artifacts for detailed metrics and graphs

        ### ðŸ” Quick Links
        - Response Times Graph
        - Throughput Graph
        - Error Analysis

        > Note: Full dashboard will be available after merging to main branch."

        echo "$PR_COMMENT" | gh pr comment ${{ github.event.pull_request.number }} --body-file -
      env:
        GITHUB_TOKEN: ${{ github.token }}

    - name: Archive test results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: jmeter-test-results
        path: results/dashboard
        retention-days: 30

    - name: Archive detailed results
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: jmeter-detailed-results
        path: |
          results/results.jtl
          results/jmeter.log
        retention-days: 30

  deploy-pages:
    if: github.ref == 'refs/heads/main'  # Only run on main branch
    needs: performance-test
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
    - name: Download dashboard artifact
      uses: actions/download-artifact@v4
      with:
        name: jmeter-test-results
        path: dashboard

    - name: Setup Pages
      uses: actions/configure-pages@v4

    - name: Upload Pages artifact
      uses: actions/upload-pages-artifact@v3
      with:
        path: dashboard

    - name: Deploy to GitHub Pages
      id: deployment
      uses: actions/deploy-pages@v4
